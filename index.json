[{"authors":null,"categories":null,"content":"Hello world! I recently finalized my PhD studies at the University of Edinburgh, where I was advised by Dr. Rico Sennrich and Dr. Ivan Titov. My research aims to explore and improve the extent of language understanding in neural machine translation (NMT) and (multi-lingual) language modeling. Additionally, I\u0026rsquo;m interested in developing methods that enable large language models (LLMs) to reason about and generate natural language in a manner that is aligned with principles of fairness and safety.\nWork completed in the course of my PhD candidacy has demonstrated that NMT models rely on shallow heuristics when inferring the right sense of ambiguous words, and improved the ability of transformer models to represent lexical and contextual information. More recently, we showcased that state-of-the-art translation and multi-lingual language models perform poorly on tasks that incorporate commonsense reasoning. Related phenomena, such as co-reference resolution, discourse processing, and translation of figurative language are also among my varied research interests.\nIn the past, I completed several research internships, including one with the MOSAIC group at the Allen Institute of Artificial Intelligence, where I investigated commonsense reasoning abilities of state-of-the-art models of language. My most recent internship experiences centered around injecting factual knowledge into task-oriented dialogue systems at Amazon and the development of training objectives for LLMs that are informed by insights from language processing in the human brain at the University of Zurich.\nIn my spare time, I enjoy bouldering, acrobatics, music, learning new things, and caring for my miniature orchard.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://demelin.github.io/author/denis-emelin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/denis-emelin/","section":"authors","summary":"Hello world! I recently finalized my PhD studies at the University of Edinburgh, where I was advised by Dr. Rico Sennrich and Dr. Ivan Titov. My research aims to explore and improve the extent of language understanding in neural machine translation (NMT) and (multi-lingual) language modeling.","tags":null,"title":"Denis Emelin","type":"authors"},{"authors":["Denis Emelin","Daniele Bonadiman","Sawsan Alqahtani","Yi Zhang","Saab Mansour"],"categories":[],"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"c8beecf907a20ebf87b906ad31818ac8","permalink":"https://demelin.github.io/publication/injecting/","publishdate":"2022-12-07T14:14:05Z","relpermalink":"/publication/injecting/","section":"publication","summary":"This paper utilizes light-weight adapters that can be easily integrated with PLMs and serve as a repository for facts learned from different KBs and introduces Knowledge Probing using Response Selection (KPRS) – a probe designed specifically for TOD models.","tags":["task oriented dialogue","emnlp","knowledge retrieval","adapters","langauge models"],"title":"Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems","type":"publication"},{"authors":["Niccolò Campolungo","Tommaso Pasini","Denis Emelin","Roberto Navigli"],"categories":[],"content":"","date":1657411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657411200,"objectID":"25b7595031f56dfef8283375ec4522fa","permalink":"https://demelin.github.io/publication/reducing/","publishdate":"2020-11-21T14:14:05Z","relpermalink":"/publication/reducing/","section":"publication","summary":"We provide a novel approach for automatically creating high-precision sense-annotated parallel corpora, and put forward a specifically tailored fine-tuning strategy for exploiting these sense annotations during training without introducing any additional requirement at inference time, for improved word sense disambiguation in machine translation.","tags":["translation","naacl","data biases","word sense disambiguation","data augmentation","fine-tuning strategies"],"title":"Reducing Disambiguation Biases in NMT by Leveraging Explicit Word Sense Information","type":"publication"},{"authors":["The BIG Bench Collective"],"categories":[],"content":"","date":1654819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654819200,"objectID":"c9bf1cdad0a0127e309940da29ca888a","permalink":"https://demelin.github.io/publication/bench/","publishdate":"2020-11-21T14:14:05Z","relpermalink":"/publication/bench/","section":"publication","summary":"We introduce the Beyond the Imitation Game benchmark (BIG-bench) to inform future research into (large-scale) language modeling, prepare for disruptive new model capabilities, and ameliorate socially harmful effects. A thorough evaluation of state-of-the-art language models illustrates the challenging nature of BIG-bench.","tags":["natural language understanding","natural language generation","language models","benchmark","collaboration"],"title":"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models","type":"publication"},{"authors":["Denis Emelin","Rico Sennrich"],"categories":[],"content":"","date":1636243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636243200,"objectID":"aa200ca585c08b6f97b85d877bc6a7d6","permalink":"https://demelin.github.io/publication/winox/","publishdate":"2020-11-21T14:14:05Z","relpermalink":"/publication/winox/","section":"publication","summary":"We introduce the novel Wino-X benchmark to investigate whether translation models can perform coreference resolution that requires commonsense knowledge and whether multilingual language models are capable of commonsense reasoning across multiple languages. Our findings indicate that models are prone to biases and often fail to identify disambiguating information.","tags":["translation","coreference resolution","commonsense reasoning","emnlp","data biases"],"title":"Wino-X: Multilingual Winograd Schemas for Commonsense Reasoning and Coreference Resolution","type":"publication"},{"authors":["Denis Emelin","Ronan Le Bras","Jena D. Hwang","Maxwell Forbes","Yejin Choi"],"categories":[],"content":"","date":1609372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609372800,"objectID":"c9845fa53a66d031c5ca222ab3ed63c5","permalink":"https://demelin.github.io/publication/moral/","publishdate":"2020-12-31T14:14:05Z","relpermalink":"/publication/moral/","section":"publication","summary":"We investingate the ability of neural and classification models to reason about (im)moral behavior grounded in concrete, structured, social situations.","tags":["natural language understanding","natural language generation","social reasoning","commonsense reasoning","dataset"],"title":"Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences","type":"publication"},{"authors":["Denis Emelin","Ivan Titov","Rico Sennrich"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"6f0e61940cbf3609c7e0030eb93e1236","permalink":"https://demelin.github.io/publication/adversarial/","publishdate":"2020-11-21T14:14:05Z","relpermalink":"/publication/adversarial/","section":"publication","summary":"We introduce a method for the prediction of disambiguation errors based on statistical data properties, and develop a simple adversarial attack strategy that minimally perturbs sentences in order to elicit disambiguation errors to further probe the robustness of translation models.","tags":["translation","emnlp","adversarial","data biases","word sense disambiguation"],"title":"Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks","type":"publication"},{"authors":["Denis Emelin","Ivan Titov","Rico Sennrich"],"categories":[],"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"70d32a4e57e57527878b4b65889a86c7","permalink":"https://demelin.github.io/publication/bottleneck/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/bottleneck/","section":"publication","summary":"We argue that the need to represent and propagate lexical features in each layer limits the transformer’s capacity for learning and representing contextual information. To alleviate this bottleneck, we introduce gated shortcut connections between the embedding layer and each subsequent layer within the encoder and decoder, which enables the model to access relevant lexical content dynamically, without expending limited resources on storing it within intermediate states.","tags":["translation","wmt","transformer","improved architecture","word sense disambiguation"],"title":"Widening the Representation Bottleneck in Neural Machine Translation with Lexical Shortcuts","type":"publication"},{"authors":["Barry Haddow","Nikolay Bogoychev","Denis Emelin","Ulrich Germann","Roman Grundkiewicz","Kenneth Heafield","Antonio Valerio Miceli Barone","Rico Sennrich"],"categories":[],"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"5565f46603075995118cbca935a1864b","permalink":"https://demelin.github.io/publication/wmt18/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/publication/wmt18/","section":"publication","summary":"The University of Edinburgh made submissions to all 14 language pairs in the news translation task, with strong performances in most pairs. We introduce new RNN-variant, mixed RNN/Transformer ensembles, data selection and weighting, and extensions to back-translation.","tags":["translation","wmt","shared task"],"title":"The University of Edinburgh's Submissions to the WMT18 News Translation Task","type":"publication"},{"authors":["Denis Emelin"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9004658dc159b523e346f0669d5c5b56","permalink":"https://demelin.github.io/project/nematode/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/nematode/","section":"project","summary":"An extendable neural machine translation toolkit built around the Transformer model and implemented in TensorFlow. Supports multi-GPU training and gradient aggregation for large-scale experimentation. Transformer implementation now part of [Nematus](https://github.com/EdinburghNLP/nematus).","tags":["translation","NMT","toolkit","TensorFlow"],"title":"1. Nematode","type":"project"},{"authors":["Denis Emelin"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c387558a1a625215bc503a66157d0c76","permalink":"https://demelin.github.io/project/nce/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/nce/","section":"project","summary":"PyTorch re-implementation of the [*Noise Contrastive Estimation*](http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf) algorithm. Created as a practice exercise.","tags":["re-implementation","nce","algorithm","pytorch"],"title":"2. Re-implementation: Noise Contrastive Estimation","type":"project"},{"authors":["Denis Emelin"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a14438af3c3b225883731ffcb327ab04","permalink":"https://demelin.github.io/project/sent_sim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/sent_sim/","section":"project","summary":"PyTorch re-implementation of Mueller's et al., [*Siamese Recurrent Architectures for Learning Sentence Similarity.*](https://dl.acm.org/doi/10.5555/3016100.3016291) (AAAI, 2016). Created as a practice exercise.","tags":["re-implementation","pytorch","similarity"],"title":"3. Re-implementation: Sentence Similarity Classifier","type":"project"},{"authors":["Denis Emelin"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e0e37f7bc1986f07a7fb18608e9f2e16","permalink":"https://demelin.github.io/project/idgan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/idgan/","section":"project","summary":"Master thesis project. A fully unsupervised model developed for automated, language-agnostic simplification of natural language sentences via information density reduction. Implemented in TensorFlow. Inconclusive results, not actively maintained.","tags":["GAN","TensorFlow","information theory"],"title":"4. IDGAN","type":"project"}]